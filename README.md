# ğŸš€ Proyecto Dask: AnÃ¡lisis Paralelo y Escalable de Datos Masivos

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto **evalÃºa y compara** el rendimiento de **Dask** vs **Pandas** para el anÃ¡lisis de datos masivos. Demuestra cuÃ¡ndo usar cada herramienta y por quÃ©, con ejemplos prÃ¡cticos y resultados medibles.

### ğŸ¯ Objetivo

Demostrar que **Dask es mejor para archivos grandes** (>1GB) que no caben en memoria, mientras que **Pandas es mÃ¡s rÃ¡pido para archivos pequeÃ±os** (<500MB).

---

## ğŸ¤” Â¿QuÃ© es este proyecto?

### El Problema

Imagina que tienes un archivo Excel **gigante**:

```
ğŸ“Š Tu archivo: 5 GB de datos
ğŸ’» Tu computadora: 8 GB de RAM
âŒ Pandas intenta cargar TODO â†’ Â¡CRASH! ğŸ’¥
```

**Pandas**:
- âœ… Funciona bien con archivos pequeÃ±os (< 500 MB)
- âŒ Falla con archivos grandes (> 1 GB)
- âŒ No usa todos los nÃºcleos del procesador
- âŒ Lento cuando hay muchos datos

### La SoluciÃ³n: Dask

**Dask**:
- âœ… Divide el archivo en pedazos pequeÃ±os (chunks)
- âœ… Procesa cada pedazo por separado
- âœ… Usa todos los nÃºcleos del procesador (paralelismo)
- âœ… Puede manejar archivos de cualquier tamaÃ±o

**AnalogÃ­a Simple**:
- **Pandas** = Intentar cargar un camiÃ³n completo de una vez â†’ Se rompe
- **Dask** = Cargar el camiÃ³n en varios viajes pequeÃ±os â†’ Funciona perfecto

---

## ğŸ“¦ Â¿QuÃ© hace cada entrega?

### ğŸ“ Entrega 2: "Aprender sobre Dask"

**Â¿QuÃ© hace?**
- Te enseÃ±a cÃ³mo funciona Dask
- Muestra ejemplos bÃ¡sicos
- Compara conceptos teÃ³ricos

**Archivos**:
- `setup_dataset.py` - Configura el proyecto
- `explore_dask.py` - Ejemplos prÃ¡cticos

**Ejecutar**:
```bash
python entregas/entrega_2/setup_dataset.py
python entregas/entrega_2/explore_dask.py
```

**Resultado**: Entiendes quÃ© es Dask y cÃ³mo funciona.

---

### ğŸ“ Entrega 3: "Usar Dask con datos reales"

**Â¿QuÃ© hace?**
1. **Lee un archivo grande** (que Pandas no puede)
2. **Limpia los datos** (elimina duplicados, valores nulos)
3. **Transforma los datos** (cambia formatos, crea nuevas columnas)
4. **Agrupa y resume** (calcula promedios, sumas, etc.)

**Archivos**:
- `read_data_dask.py` - Lee el archivo y compara con Pandas
- `transform_data_dask.py` - Limpia y transforma los datos
- `generate_sample_data.py` - Genera datos de prueba (si no tienes dataset)

**Ejecutar**:
```bash
# Si no tienes dataset, genera uno:
python entregas/entrega_3/generate_sample_data.py

# Luego procesa:
python entregas/entrega_3/read_data_dask.py
python entregas/entrega_3/transform_data_dask.py
```

**Resultado**: Tienes datos limpios y procesados listos para analizar.

---

### ğŸ“ Entrega 4: "Comparar Pandas vs Dask"

**Â¿QuÃ© hace?**
- Ejecuta las **mismas operaciones** con ambas herramientas
- Mide el **tiempo** que tarda cada una
- Mide la **memoria** que usa cada una
- Calcula cuÃ¡l es **mÃ¡s rÃ¡pida**

**Archivo**:
- `compare_pandas_dask.py` - Hace las comparaciones

**Ejecutar**:
```bash
python entregas/entrega_4/compare_pandas_dask.py
```

**Resultado**: Sabes exactamente cuÃ¡ndo usar cada herramienta.

---

### ğŸ“ Entrega 5: "Mostrar los resultados"

**Â¿QuÃ© hace?**
- Crea **grÃ¡ficos bonitos** comparando Pandas y Dask
- Genera un **reporte** con las conclusiones
- Muestra **tablas** con todos los nÃºmeros

**Archivo**:
- `visualize_results.py` - Genera grÃ¡ficos y reportes

**Ejecutar**:
```bash
python entregas/entrega_5/visualize_results.py
```

**Resultado**: Tienes visualizaciones profesionales de los resultados.

---

## ğŸš€ CÃ³mo Usar el Proyecto

### OpciÃ³n 1: Todo AutomÃ¡tico (Recomendado) â­

```bash
# 1. Instalar dependencias
python check_dependencies.py

# 2. Generar datos de prueba (si no tienes dataset)
python entregas/entrega_3/generate_sample_data.py

# 3. Ejecutar todo
python run_complete_pipeline.py
```

**Â¡Listo!** Los resultados estarÃ¡n en `results/`

---

### OpciÃ³n 2: Paso a Paso

```bash
# 1. Verificar e instalar dependencias
python check_dependencies.py

# 2. Configurar (solo la primera vez)
python entregas/entrega_2/setup_dataset.py

# 3. Explorar Dask
python entregas/entrega_2/explore_dask.py

# 4. Generar datos (si no tienes dataset)
python entregas/entrega_3/generate_sample_data.py

# 5. Leer datos
python entregas/entrega_3/read_data_dask.py

# 6. Transformar datos
python entregas/entrega_3/transform_data_dask.py

# 7. Comparar
python entregas/entrega_4/compare_pandas_dask.py

# 8. Visualizar
python entregas/entrega_5/visualize_results.py
```

---

## ğŸ“Š Resultados que Obtienes

### GrÃ¡ficos Generados (en `results/figures/`):

1. **time_comparison.png** 
   - Muestra cuÃ¡nto tiempo tarda cada herramienta
   - Â¿CuÃ¡l es mÃ¡s rÃ¡pida?

2. **memory_comparison.png**
   - Muestra cuÃ¡nta memoria usa cada herramienta
   - Â¿CuÃ¡l es mÃ¡s eficiente?

3. **speedup_analysis.png**
   - Muestra cuÃ¡ntas veces mÃ¡s rÃ¡pido es Dask
   - AnÃ¡lisis de velocidad

4. **comparison_table.png**
   - Tabla con todos los nÃºmeros
   - ComparaciÃ³n completa

### Reportes Generados (en `results/reports/`):

- **summary_report.txt**
  - Conclusiones principales
  - MÃ©tricas detalladas
  - Recomendaciones

### Datos Procesados (en `data/processed/`):

- **processed_data.parquet** - Datos limpios y transformados
- **benchmark_results.csv** - MÃ©tricas de rendimiento

---

## ğŸ“ Conceptos Clave Explicados Simple

### 1. Chunks (Bloques)

**Â¿QuÃ© es?**
Dask divide el archivo grande en pedazos pequeÃ±os.

**Ejemplo**:
```
Archivo grande (5 GB)
    â†“
Dask lo divide en:
  - Chunk 1 (100 MB)
  - Chunk 2 (100 MB)
  - Chunk 3 (100 MB)
  - ... (50 chunks en total)
```

**Ventaja**: Solo carga en memoria lo que necesita, no todo.

---

### 2. Paralelismo

**Â¿QuÃ© es?**
Procesar varias cosas al mismo tiempo.

**Pandas**:
```
[Tarea 1] â†’ [Tarea 2] â†’ [Tarea 3]
Una a la vez (secuencial)
```

**Dask**:
```
[Tarea 1] â”
[Tarea 2] â”œâ†’ Todas al mismo tiempo (paralelo)
[Tarea 3] â”˜
```

**Ventaja**: MÃ¡s rÃ¡pido porque usa todos los nÃºcleos del CPU.

---

### 3. Lazy Evaluation (EvaluaciÃ³n Diferida)

**Â¿QuÃ© es?**
Dask planifica primero, ejecuta despuÃ©s.

**Pandas**:
```
Leer â†’ Procesar â†’ Mostrar
(Hace todo inmediatamente)
```

**Dask**:
```
Planear â†’ (esperar) â†’ Ejecutar cuando sea necesario
(Puede optimizar antes de ejecutar)
```

**Ventaja**: Puede optimizar antes de ejecutar.

---

## ğŸ“ˆ Resultados Esperados

### Con un Dataset de 2 GB:

| OperaciÃ³n | Pandas | Dask | Ventaja |
|-----------|--------|------|---------|
| Lectura | âŒ Falla | âœ… 30s | Dask funciona |
| Filtrado | âŒ Falla | âœ… 45s | Dask funciona |
| AgrupaciÃ³n | âŒ Falla | âœ… 60s | Dask funciona |

**ConclusiÃ³n**: Con archivos grandes, **solo Dask funciona**.

---

### Con un Dataset de 500 MB:

| OperaciÃ³n | Pandas | Dask | Ventaja |
|-----------|--------|------|---------|
| Lectura | âœ… 5s | âœ… 8s | Pandas mÃ¡s rÃ¡pido |
| Filtrado | âœ… 3s | âœ… 4s | Pandas mÃ¡s rÃ¡pido |
| AgrupaciÃ³n | âœ… 10s | âœ… 12s | Pandas mÃ¡s rÃ¡pido |

**ConclusiÃ³n**: Con archivos pequeÃ±os, **Pandas es mÃ¡s rÃ¡pido** (menos overhead).

---

### Regla General:

| TamaÃ±o del Archivo | Usa |
|-------------------|-----|
| < 500 MB | **Pandas** (mÃ¡s rÃ¡pido) |
| 500 MB - 1 GB | **Cualquiera** (similar) |
| > 1 GB | **Dask** (Ãºnica opciÃ³n) |

---

## ğŸ› ï¸ InstalaciÃ³n

### 1. Clonar el repositorio:
```bash
git clone <url-del-repositorio>
cd Dask
```

### 2. Crear un entorno virtual (recomendado):
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias:

**OpciÃ³n A - AutomÃ¡tica (Recomendada):**
```bash
python check_dependencies.py
```
Este script verificarÃ¡ e instalarÃ¡ automÃ¡ticamente las dependencias faltantes.

**OpciÃ³n B - Manual:**
```bash
pip install -r requirements.txt
```

**Si tienes problemas, instala las dependencias principales:**
```bash
pip install dask pandas numpy matplotlib seaborn psutil tqdm pyarrow fastparquet
```

---

## ğŸ“ Estructura del Proyecto

```
Dask/
â”œâ”€â”€ entregas/                    # CÃ³digo organizado por entregas
â”‚   â”œâ”€â”€ entrega_2/              # âœ… Fundamentos teÃ³ricos de Dask
â”‚   â”‚   â”œâ”€â”€ setup_dataset.py    # ConfiguraciÃ³n inicial
â”‚   â”‚   â”œâ”€â”€ explore_dask.py     # Demostraciones de Dask
â”‚   â”‚   â””â”€â”€ README.md           # DocumentaciÃ³n especÃ­fica
â”‚   â”œâ”€â”€ entrega_3/              # âœ… Procesamiento de datos
â”‚   â”‚   â”œâ”€â”€ read_data_dask.py   # Lectura de datasets
â”‚   â”‚   â”œâ”€â”€ transform_data_dask.py  # Transformaciones
â”‚   â”‚   â”œâ”€â”€ generate_sample_data.py  # Generador de datos sintÃ©ticos
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ entrega_4/              # âœ… ComparaciÃ³n de rendimiento
â”‚   â”‚   â”œâ”€â”€ compare_pandas_dask.py   # Benchmark completo
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ entrega_5/              # âœ… VisualizaciÃ³n
â”‚       â”œâ”€â”€ visualize_results.py    # GrÃ¡ficos y reportes
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ data/                       # Datasets (no incluidos en git)
â”‚   â”œâ”€â”€ raw/                   # Datos originales (CSV)
â”‚   â””â”€â”€ processed/              # Datos procesados (Parquet)
â”‚
â”œâ”€â”€ results/                    # Resultados generados
â”‚   â”œâ”€â”€ figures/               # GrÃ¡ficos (PNG)
â”‚   â”‚   â”œâ”€â”€ time_comparison.png
â”‚   â”‚   â”œâ”€â”€ memory_comparison.png
â”‚   â”‚   â”œâ”€â”€ speedup_analysis.png
â”‚   â”‚   â””â”€â”€ comparison_table.png
â”‚   â””â”€â”€ reports/               # Reportes (TXT)
â”‚       â””â”€â”€ summary_report.txt
â”‚
â”œâ”€â”€ src/                        # CÃ³digo reutilizable
â”‚   â”œâ”€â”€ utils/                 # Utilidades
â”‚   â”‚   â””â”€â”€ config.py          # ConfiguraciÃ³n centralizada
â”‚   â””â”€â”€ benchmarks/            # Herramientas de benchmarking
â”‚       â””â”€â”€ benchmark_utils.py
â”‚
â”œâ”€â”€ check_dependencies.py       # Verificador de dependencias
â”œâ”€â”€ run_complete_pipeline.py    # Script maestro (ejecuta todo)
â”œâ”€â”€ requirements.txt            # Dependencias del proyecto
â””â”€â”€ README.md                   # Este archivo
```

---

## âœ… Requisitos

### Software
- **Python 3.8+** (recomendado 3.9 o superior)
- Todas las dependencias en `requirements.txt`

### Hardware Recomendado
- **RAM**: MÃ­nimo 8 GB (recomendado 16 GB)
- **Disco**: 5-10 GB libres para datasets y resultados
- **CPU**: MÃºltiples nÃºcleos (Dask aprovecha paralelismo)

### Datos
- **OpciÃ³n 1**: Dataset CSV de 1-5 GB en `data/raw/`
- **OpciÃ³n 2**: Usar generador de datos sintÃ©ticos (incluido)

### Dependencias Principales
- `dask` - Procesamiento paralelo y distribuido
- `pandas` - AnÃ¡lisis de datos (comparaciÃ³n)
- `numpy` - Operaciones numÃ©ricas
- `matplotlib` / `seaborn` - Visualizaciones
- `psutil` - MediciÃ³n de memoria
- `pyarrow` / `fastparquet` - Formato Parquet

---

## ğŸ†˜ SoluciÃ³n de Problemas

### âŒ Error: "ModuleNotFoundError: No module named 'dask'"
**SoluciÃ³n:**
```bash
python check_dependencies.py
# O manualmente:
pip install -r requirements.txt
```

### âŒ Error: "No se encontraron archivos de datos"
**SoluciÃ³n:**
```bash
# Generar datos sintÃ©ticos
python entregas/entrega_3/generate_sample_data.py

# O colocar un CSV en data/raw/
```

### âŒ Error: "Directory not found"
**SoluciÃ³n:**
```bash
python entregas/entrega_2/setup_dataset.py
```

### âŒ Pandas falla con archivo grande
**Es normal**: Pandas no puede con archivos muy grandes. Eso es exactamente lo que demuestra el proyecto.

### âŒ Error al guardar en Parquet
**SoluciÃ³n**: El script intentarÃ¡ automÃ¡ticamente con diferentes engines. Si falla, guardarÃ¡ como CSV.

---

## ğŸ“‹ Plan de Trabajo

- âœ… **Semana 1**: SelecciÃ³n del dataset y diseÃ±o del experimento
- âœ… **Semana 2**: RevisiÃ³n del funcionamiento teÃ³rico de Dask (COMPLETA)
- âœ… **Semana 3**: Lectura y primeras transformaciones con Dask (COMPLETA)
- âœ… **Semana 4**: ImplementaciÃ³n de las mismas tareas con Pandas para comparaciÃ³n (COMPLETA)
- âœ… **Semana 5**: MediciÃ³n, anÃ¡lisis y visualizaciÃ³n de resultados (COMPLETA)
- â³ **Semana 6**: RedacciÃ³n del informe tÃ©cnico en formato IEEE
- â³ **Semana 7**: Ajustes finales, documentaciÃ³n y preparaciÃ³n del repositorio

---

## ğŸ¯ Estado del Proyecto

âœ… **CÃ³digo Completo**: Entregas 2-5 implementadas y listas para usar
âœ… **DocumentaciÃ³n**: Completa y actualizada
âœ… **Scripts Funcionales**: Todos probados y documentados
âœ… **Generador de Datos**: Incluido para pruebas sin dataset real
âœ… **Visualizaciones**: GrÃ¡ficos y reportes automÃ¡ticos
â³ **Pendiente**: Dataset real (opcional) e informe final IEEE

---

## ğŸ“ Resumen en 3 Puntos

1. **Dask es mejor para archivos grandes** que no caben en memoria
2. **Pandas es mÃ¡s rÃ¡pido para archivos pequeÃ±os** (menos overhead)
3. **Este proyecto demuestra cuÃ¡ndo usar cada uno** con datos reales

---

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n de Dask](https://docs.dask.org/)
- [Tutorial de Dask DataFrames](https://docs.dask.org/en/stable/dataframe.html)
- [Ejemplos de Dask](https://examples.dask.org/)

---

## ğŸ‘¤ Autor

**Mauro Espinoza**

---

## ğŸ“„ Licencia

Este proyecto es parte de un trabajo acadÃ©mico.

---

## ğŸš€ Â¡Listo para Empezar!

```bash
# 1. Instalar dependencias
python check_dependencies.py

# 2. Generar datos (opcional)
python entregas/entrega_3/generate_sample_data.py

# 3. Ejecutar todo
python run_complete_pipeline.py
```

**Â¡Ã‰xito con tu proyecto!** ğŸ‰
